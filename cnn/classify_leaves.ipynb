{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.644907Z",
     "start_time": "2025-08-27T15:02:53.981167Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.chdir('/root/autodl-tmp/train/code')\n",
    "os.getcwd()"
   ],
   "id": "36e6b5818fb074f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.659907Z",
     "start_time": "2025-08-27T15:02:59.649908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, imd_dir, is_train=True, transform = None, label_map = None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.imd_dir = imd_dir\n",
    "        self.is_train = is_train\n",
    "\n",
    "        if label_map is None and self.is_train:\n",
    "            self._create_label_map()\n",
    "\n",
    "    def _create_label_map(self):\n",
    "        unique_labels = sorted(self.data['label'].unique())\n",
    "        self.label_map = {label:idx for idx,label in enumerate(unique_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_rel_path = self.data.iloc[idx]['image']\n",
    "        img_path = os.path.join(self.imd_dir, img_rel_path)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_train:\n",
    "            label_text = self.data.iloc[idx]['label']\n",
    "            label_idx = self.label_map[label_text]\n",
    "            return image, torch.tensor(label_idx, dtype=torch.long)\n",
    "        else:\n",
    "            return image\n"
   ],
   "id": "62a40fa15cac3808",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.675908Z",
     "start_time": "2025-08-27T15:02:59.663911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])"
   ],
   "id": "7f671315682c4a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.722418Z",
     "start_time": "2025-08-27T15:02:59.681908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_csv = '../data/classify-leaves/train.csv'\n",
    "test_csv = '../data/classify-leaves/test.csv'\n",
    "img_root_dir = '../data/classify-leaves/images'\n",
    "\n",
    "train_dataset = CustomImageDataset(train_csv, img_root_dir, is_train=True, transform=train_transform)\n",
    "label_map = train_dataset.label_map\n",
    "print(f\"Using label mapping: {label_map}\")"
   ],
   "id": "d265c4b7dc0c0d63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label mapping: {'abies_concolor': 0, 'abies_nordmanniana': 1, 'acer_campestre': 2, 'acer_ginnala': 3, 'acer_griseum': 4, 'acer_negundo': 5, 'acer_palmatum': 6, 'acer_pensylvanicum': 7, 'acer_platanoides': 8, 'acer_pseudoplatanus': 9, 'acer_rubrum': 10, 'acer_saccharinum': 11, 'acer_saccharum': 12, 'aesculus_flava': 13, 'aesculus_glabra': 14, 'aesculus_hippocastamon': 15, 'aesculus_pavi': 16, 'ailanthus_altissima': 17, 'albizia_julibrissin': 18, 'amelanchier_arborea': 19, 'amelanchier_canadensis': 20, 'amelanchier_laevis': 21, 'asimina_triloba': 22, 'betula_alleghaniensis': 23, 'betula_jacqemontii': 24, 'betula_lenta': 25, 'betula_nigra': 26, 'betula_populifolia': 27, 'broussonettia_papyrifera': 28, 'carpinus_betulus': 29, 'carpinus_caroliniana': 30, 'carya_cordiformis': 31, 'carya_glabra': 32, 'carya_ovata': 33, 'carya_tomentosa': 34, 'castanea_dentata': 35, 'catalpa_bignonioides': 36, 'catalpa_speciosa': 37, 'cedrus_atlantica': 38, 'cedrus_deodara': 39, 'cedrus_libani': 40, 'celtis_occidentalis': 41, 'celtis_tenuifolia': 42, 'cercidiphyllum_japonicum': 43, 'cercis_canadensis': 44, 'chamaecyparis_pisifera': 45, 'chamaecyparis_thyoides': 46, 'chionanthus_retusus': 47, 'chionanthus_virginicus': 48, 'cladrastis_lutea': 49, 'cornus_florida': 50, 'cornus_kousa': 51, 'cornus_mas': 52, 'crataegus_crus-galli': 53, 'crataegus_laevigata': 54, 'crataegus_phaenopyrum': 55, 'crataegus_pruinosa': 56, 'crataegus_viridis': 57, 'cryptomeria_japonica': 58, 'diospyros_virginiana': 59, 'eucommia_ulmoides': 60, 'evodia_daniellii': 61, 'fagus_grandifolia': 62, 'ficus_carica': 63, 'fraxinus_nigra': 64, 'fraxinus_pennsylvanica': 65, 'ginkgo_biloba': 66, 'gleditsia_triacanthos': 67, 'gymnocladus_dioicus': 68, 'halesia_tetraptera': 69, 'ilex_opaca': 70, 'juglans_cinerea': 71, 'juglans_nigra': 72, 'juniperus_virginiana': 73, 'koelreuteria_paniculata': 74, 'larix_decidua': 75, 'liquidambar_styraciflua': 76, 'liriodendron_tulipifera': 77, 'maclura_pomifera': 78, 'magnolia_acuminata': 79, 'magnolia_denudata': 80, 'magnolia_grandiflora': 81, 'magnolia_macrophylla': 82, 'magnolia_stellata': 83, 'magnolia_tripetala': 84, 'magnolia_virginiana': 85, 'malus_baccata': 86, 'malus_coronaria': 87, 'malus_floribunda': 88, 'malus_hupehensis': 89, 'malus_pumila': 90, 'metasequoia_glyptostroboides': 91, 'morus_alba': 92, 'morus_rubra': 93, 'nyssa_sylvatica': 94, 'ostrya_virginiana': 95, 'oxydendrum_arboreum': 96, 'paulownia_tomentosa': 97, 'phellodendron_amurense': 98, 'picea_abies': 99, 'picea_orientalis': 100, 'picea_pungens': 101, 'pinus_bungeana': 102, 'pinus_cembra': 103, 'pinus_densiflora': 104, 'pinus_echinata': 105, 'pinus_flexilis': 106, 'pinus_koraiensis': 107, 'pinus_nigra': 108, 'pinus_parviflora': 109, 'pinus_peucea': 110, 'pinus_pungens': 111, 'pinus_resinosa': 112, 'pinus_rigida': 113, 'pinus_strobus': 114, 'pinus_sylvestris': 115, 'pinus_taeda': 116, 'pinus_thunbergii': 117, 'pinus_virginiana': 118, 'pinus_wallichiana': 119, 'platanus_acerifolia': 120, 'platanus_occidentalis': 121, 'populus_deltoides': 122, 'populus_grandidentata': 123, 'populus_tremuloides': 124, 'prunus_pensylvanica': 125, 'prunus_sargentii': 126, 'prunus_serotina': 127, 'prunus_serrulata': 128, 'prunus_subhirtella': 129, 'prunus_virginiana': 130, 'prunus_yedoensis': 131, 'pseudolarix_amabilis': 132, 'ptelea_trifoliata': 133, 'pyrus_calleryana': 134, 'quercus_acutissima': 135, 'quercus_alba': 136, 'quercus_bicolor': 137, 'quercus_cerris': 138, 'quercus_coccinea': 139, 'quercus_imbricaria': 140, 'quercus_macrocarpa': 141, 'quercus_marilandica': 142, 'quercus_michauxii': 143, 'quercus_montana': 144, 'quercus_muehlenbergii': 145, 'quercus_nigra': 146, 'quercus_palustris': 147, 'quercus_phellos': 148, 'quercus_robur': 149, 'quercus_shumardii': 150, 'quercus_stellata': 151, 'quercus_velutina': 152, 'quercus_virginiana': 153, 'robinia_pseudo-acacia': 154, 'salix_babylonica': 155, 'salix_caroliniana': 156, 'salix_matsudana': 157, 'salix_nigra': 158, 'sassafras_albidum': 159, 'staphylea_trifolia': 160, 'stewartia_pseudocamellia': 161, 'styrax_japonica': 162, 'taxodium_distichum': 163, 'tilia_americana': 164, 'tilia_cordata': 165, 'tilia_europaea': 166, 'tilia_tomentosa': 167, 'tsuga_canadensis': 168, 'ulmus_americana': 169, 'ulmus_glabra': 170, 'ulmus_parvifolia': 171, 'ulmus_procera': 172, 'ulmus_pumila': 173, 'ulmus_rubra': 174, 'zelkova_serrata': 175}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.737414Z",
     "start_time": "2025-08-27T15:02:59.726416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_kfold_splits(full_dataset, n_splits=5, random_state=42):\n",
    "    kfold = KFold(n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    indices = np.arange(len(full_dataset))\n",
    "    labels = [full_dataset.data.iloc[i]['label'] for i in indices]\n",
    "\n",
    "    fold_loaders = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices, labels)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        print(f\"  Train: {len(train_idx)} samples\")\n",
    "        print(f\"  Validation: {len(val_idx)} samples\")\n",
    "\n",
    "        train_subset = Subset(full_dataset, train_idx)\n",
    "        val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "        tran_iter = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=10, pin_memory=True)\n",
    "        val_iter = DataLoader(val_subset, batch_size=32, shuffle=True, num_workers=10, pin_memory=True)\n",
    "\n",
    "        fold_loaders.append((tran_iter,val_iter))\n",
    "    return fold_loaders"
   ],
   "id": "e0fcb9b67ff5f6a8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.752420Z",
     "start_time": "2025-08-27T15:02:59.741417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lenet\n",
    "# def get_net():\n",
    "#     net = nn.Sequential(\n",
    "#         # 图片为224*224，输出大小为(224+2*3-5)/1+1=224\n",
    "#         nn.Conv2d(3, 16, kernel_size=5, stride=2),\n",
    "#         nn.ReLU(),\n",
    "#         # 池化后输出大小为(224+2*0-2)/2+1=112\n",
    "#         nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "#         # 通道扩充为32，输出大小为(112+2*0-5)/1+1=108\n",
    "#         nn.Conv2d(16, 32, kernel_size=5),\n",
    "#         nn.ReLU(),\n",
    "#         # 输出大小为(108+2*0-2)/2+1=54\n",
    "#         nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "#         nn.Flatten(),\n",
    "#         nn.Linear(32 * 54 * 54, 512),\n",
    "#         nn.Linear(512, 256),\n",
    "#         nn.Linear(256, 176)\n",
    "#     )\n",
    "#     return net\n",
    "\n",
    "# alexnet\n",
    "def get_net():\n",
    "    net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))\n",
    "    return net"
   ],
   "id": "408f514b795a6cf5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:02:59.767925Z",
     "start_time": "2025-08-27T15:02:59.756421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')\n",
    "\n"
   ],
   "id": "8fee32e979dcee5e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-27T15:02:59.772928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kfold_loaders = create_kfold_splits(train_dataset, n_splits=5)\n",
    "\n",
    "lr, num_epochs = 0.08, 10\n",
    "k_fold_nets = []\n",
    "for fold, (train_iter,val_iter) in enumerate(kfold_loaders):\n",
    "    print(f'训练第{fold+1}折')\n",
    "    net = get_net()\n",
    "    train_ch6(net, train_iter, val_iter, num_epochs, lr, d2l.try_gpu())\n",
    "    k_fold_nets.append(net)\n",
    "\n",
    "d2l.plt.show()"
   ],
   "id": "950724e016ccb88b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "  Train: 14682 samples\n",
      "  Validation: 3671 samples\n",
      "Fold 2/5\n",
      "  Train: 14682 samples\n",
      "  Validation: 3671 samples\n",
      "Fold 3/5\n",
      "  Train: 14682 samples\n",
      "  Validation: 3671 samples\n",
      "Fold 4/5\n",
      "  Train: 14683 samples\n",
      "  Validation: 3670 samples\n",
      "Fold 5/5\n",
      "  Train: 14683 samples\n",
      "  Validation: 3670 samples\n",
      "第1折\n",
      "training on cpu\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_dataset = CustomImageDataset(test_csv, img_root_dir, is_train=False, transform=test_transform)\n",
    "test_iter = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "id": "4be15c90f303068b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def assemble_predict(nets, dataloader, device):\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            X = X.to(device)\n",
    "            logits_sum = None\n",
    "\n",
    "            for net in nets:\n",
    "                net.eval()\n",
    "                logits = net(X)\n",
    "                if logits_sum is None:\n",
    "                    logits_sum = logits\n",
    "                else:\n",
    "                    logits_sum += logits\n",
    "\n",
    "            avg_logits = logits_sum / len(net)\n",
    "            preds = avg_logits.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "    return all_preds"
   ],
   "id": "af9ad8938731e664"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_preds = assemble_predict(k_fold_nets, test_iter, device = d2l.try_gpu())\n",
    "\n",
    "idx_to_label = {v: k for k, v in label_map.items()}\n",
    "pred_labels = [idx_to_label[idx] for idx in test_preds]\n",
    "\n",
    "test_img_names = test_dataset.data['image'].tolist()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'image': test_img_names,\n",
    "    'label': pred_labels\n",
    "})\n",
    "submission.to_csv('../data/classify-leaves/submission.csv', index=False)\n",
    "print(\"提交文件已保存至 ../data/classify-leaves/submission.csv\")"
   ],
   "id": "cbc67a5afbf6aa74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
